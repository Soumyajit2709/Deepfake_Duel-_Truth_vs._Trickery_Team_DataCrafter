{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63c4efc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52e49667",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArtifactDataset(Dataset):\n",
    "    def __init__(self, root_dir, mode='train', transform=None):\n",
    "        self.transform = transform\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        self.classes = []\n",
    "        for label_type in ['real', 'fake']:\n",
    "            for cls in ['human_faces', 'animals', 'vehicles']:\n",
    "                dir_path = os.path.join(root_dir, label_type, cls)\n",
    "                if not os.path.exists(dir_path):\n",
    "                    continue\n",
    "                for img_name in os.listdir(dir_path):\n",
    "                    self.image_paths.append(os.path.join(dir_path, img_name))\n",
    "                    self.labels.append(1 if label_type == 'real' else 0)\n",
    "                    self.classes.append(cls)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        class_name = self.classes[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        class_label = ['human_faces', 'animals', 'vehicles'].index(class_name)\n",
    "        return image, torch.tensor(label, dtype=torch.float32), torch.tensor(class_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a571ccbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d78f1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ArtifactDataset(\"ArtiFact_240K/train\", transform=transform)\n",
    "val_dataset = ArtifactDataset(\"ArtiFact_240K/validation\", transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b249333",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.fft\n",
    "import timm\n",
    "\n",
    "class KANVisionLSTM_FFT(nn.Module):\n",
    "    def __init__(self, backbone='xception', lstm_hidden=128, lstm_layers=1, num_classes=3):\n",
    "        super(KANVisionLSTM_FFT, self).__init__()\n",
    "\n",
    "        # Combine RGB and FFT channels\n",
    "        self.rgb_fft_proj = nn.Conv2d(6, 3, kernel_size=1)\n",
    "\n",
    "        # Load the specified backbone model\n",
    "        self.backbone_name = backbone\n",
    "        self.backbone = timm.create_model(backbone, pretrained=True, num_classes=0)\n",
    "\n",
    "        # Determine if the backbone is a Vision Transformer\n",
    "        self.is_vit = 'vit' in backbone.lower()\n",
    "\n",
    "        # Set embedding dimension based on the backbone\n",
    "        if self.is_vit:\n",
    "            self.embed_dim = self.backbone.embed_dim\n",
    "        else:\n",
    "            # For CNN backbones like XceptionNet\n",
    "            dummy_input = torch.randn(1, 3, 299, 299)\n",
    "            with torch.no_grad():\n",
    "                features = self.backbone.forward_features(dummy_input)\n",
    "            self.embed_dim = features.shape[1]\n",
    "\n",
    "        # LSTM over backbone features\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=self.embed_dim,\n",
    "            hidden_size=lstm_hidden,\n",
    "            num_layers=lstm_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=True\n",
    "        )\n",
    "\n",
    "        # Attention mechanism\n",
    "        self.attn = nn.Sequential(\n",
    "            nn.Linear(lstm_hidden * 2, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "\n",
    "        # KAN-style transformation\n",
    "        self.kernel_net = nn.Sequential(\n",
    "            nn.Linear(lstm_hidden * 2, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # Output heads\n",
    "        self.real_fake_head = nn.Linear(64, 1)\n",
    "        self.class_head = nn.Linear(64, num_classes)\n",
    "\n",
    "    def extract_fft(self, x):\n",
    "        # Compute FFT magnitude\n",
    "        fft = torch.fft.fft2(x)\n",
    "        return torch.abs(fft)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: [B, 3, H, W]\n",
    "        fft = self.extract_fft(x)\n",
    "        combined = torch.cat([x, fft], dim=1)           # [B, 6, H, W]\n",
    "        projected = self.rgb_fft_proj(combined)         # [B, 3, H, W]\n",
    "\n",
    "        # Extract features using the backbone\n",
    "        if self.is_vit:\n",
    "            tokens = self.backbone.forward_features(projected)  # [B, N, embed_dim]\n",
    "        else:\n",
    "            features = self.backbone.forward_features(projected)  # [B, embed_dim, H', W']\n",
    "            tokens = features.flatten(2).transpose(1, 2)          # [B, N, embed_dim]\n",
    "\n",
    "        lstm_out, _ = self.lstm(tokens)                 # [B, N, 2*lstm_hidden]\n",
    "\n",
    "        attn_scores = self.attn(lstm_out)               # [B, N, 1]\n",
    "        attn_weights = torch.softmax(attn_scores, dim=1)\n",
    "        pooled = (attn_weights * lstm_out).sum(dim=1)   # [B, 2*lstm_hidden]\n",
    "\n",
    "        fused = self.kernel_net(pooled)                 # [B, 64]\n",
    "\n",
    "        real_fake = torch.sigmoid(self.real_fake_head(fused))  # [B]\n",
    "        cls_pred = self.class_head(fused)                      # [B, num_classes]\n",
    "\n",
    "        return real_fake.squeeze(1), cls_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed8b7aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KANVisionLSTM_FFT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09dbe1d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KANVisionLSTM_FFT(\n",
       "  (rgb_fft_proj): Conv2d(6, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (backbone): Xception(\n",
       "    (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "    (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act1): ReLU(inplace=True)\n",
       "    (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act2): ReLU(inplace=True)\n",
       "    (block1): Block(\n",
       "      (skip): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      (skipbn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (rep): Sequential(\n",
       "        (0): SeparableConv2d(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "          (pointwise): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): SeparableConv2d(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "          (pointwise): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "    (block2): Block(\n",
       "      (skip): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      (skipbn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (rep): Sequential(\n",
       "        (0): ReLU()\n",
       "        (1): SeparableConv2d(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "          (pointwise): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): SeparableConv2d(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "          (pointwise): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "    (block3): Block(\n",
       "      (skip): Conv2d(256, 728, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      (skipbn): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (rep): Sequential(\n",
       "        (0): ReLU()\n",
       "        (1): SeparableConv2d(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "          (pointwise): Conv2d(256, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): SeparableConv2d(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "    (block4): Block(\n",
       "      (rep): Sequential(\n",
       "        (0): ReLU()\n",
       "        (1): SeparableConv2d(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): SeparableConv2d(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): ReLU(inplace=True)\n",
       "        (7): SeparableConv2d(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (8): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (block5): Block(\n",
       "      (rep): Sequential(\n",
       "        (0): ReLU()\n",
       "        (1): SeparableConv2d(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): SeparableConv2d(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): ReLU(inplace=True)\n",
       "        (7): SeparableConv2d(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (8): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (block6): Block(\n",
       "      (rep): Sequential(\n",
       "        (0): ReLU()\n",
       "        (1): SeparableConv2d(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): SeparableConv2d(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): ReLU(inplace=True)\n",
       "        (7): SeparableConv2d(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (8): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (block7): Block(\n",
       "      (rep): Sequential(\n",
       "        (0): ReLU()\n",
       "        (1): SeparableConv2d(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): SeparableConv2d(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): ReLU(inplace=True)\n",
       "        (7): SeparableConv2d(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (8): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (block8): Block(\n",
       "      (rep): Sequential(\n",
       "        (0): ReLU()\n",
       "        (1): SeparableConv2d(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): SeparableConv2d(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): ReLU(inplace=True)\n",
       "        (7): SeparableConv2d(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (8): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (block9): Block(\n",
       "      (rep): Sequential(\n",
       "        (0): ReLU()\n",
       "        (1): SeparableConv2d(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): SeparableConv2d(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): ReLU(inplace=True)\n",
       "        (7): SeparableConv2d(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (8): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (block10): Block(\n",
       "      (rep): Sequential(\n",
       "        (0): ReLU()\n",
       "        (1): SeparableConv2d(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): SeparableConv2d(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): ReLU(inplace=True)\n",
       "        (7): SeparableConv2d(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (8): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (block11): Block(\n",
       "      (rep): Sequential(\n",
       "        (0): ReLU()\n",
       "        (1): SeparableConv2d(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): SeparableConv2d(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): ReLU(inplace=True)\n",
       "        (7): SeparableConv2d(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (8): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (block12): Block(\n",
       "      (skip): Conv2d(728, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      (skipbn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (rep): Sequential(\n",
       "        (0): ReLU()\n",
       "        (1): SeparableConv2d(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): SeparableConv2d(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "    (conv3): SeparableConv2d(\n",
       "      (conv1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)\n",
       "      (pointwise): Conv2d(1024, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (bn3): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act3): ReLU(inplace=True)\n",
       "    (conv4): SeparableConv2d(\n",
       "      (conv1): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "      (pointwise): Conv2d(1536, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (bn4): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act4): ReLU(inplace=True)\n",
       "    (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
       "    (fc): Identity()\n",
       "  )\n",
       "  (lstm): LSTM(2048, 128, batch_first=True, bidirectional=True)\n",
       "  (attn): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (1): Tanh()\n",
       "    (2): Linear(in_features=128, out_features=1, bias=True)\n",
       "  )\n",
       "  (kernel_net): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (3): ReLU()\n",
       "  )\n",
       "  (real_fake_head): Linear(in_features=64, out_features=1, bias=True)\n",
       "  (class_head): Linear(in_features=64, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bcb968a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, epochs=3, lr=1e-4):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion_real_fake = nn.BCELoss()\n",
    "    criterion_class = nn.CrossEntropyLoss()\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for images, labels, class_labels in tqdm(train_loader, desc=f\"Epoch {epoch+1} Training\"):\n",
    "            images, labels, class_labels = images.to(device), labels.to(device), class_labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out_real_fake, out_class = model(images)\n",
    "            loss1 = criterion_real_fake(out_real_fake, labels)\n",
    "            loss2 = criterion_class(out_class, class_labels)\n",
    "            loss = loss1 + loss2\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1} Loss: {total_loss / len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1821a674",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training: 100%|██████████| 10500/10500 [1:33:45<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 0.5944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Training: 100%|██████████| 10500/10500 [1:33:23<00:00,  1.87it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss: 0.4880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 Training: 100%|██████████| 10500/10500 [1:32:46<00:00,  1.84it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Loss: 0.3690\n"
     ]
    }
   ],
   "source": [
    "train_model(model, train_loader, val_loader, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7465fcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader):\n",
    "    model.eval()\n",
    "    preds_rf, trues_rf = [], []\n",
    "    preds_cls, trues_cls = [], []\n",
    "    with torch.no_grad():\n",
    "        for images, labels, class_labels in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            class_labels = class_labels.to(device)\n",
    "            out_real_fake, out_class = model(images)\n",
    "            preds_rf += (out_real_fake > 0.5).cpu().numpy().tolist()\n",
    "            trues_rf += labels.cpu().numpy().tolist()\n",
    "            preds_cls += torch.argmax(out_class, dim=1).cpu().numpy().tolist()\n",
    "            trues_cls += class_labels.cpu().numpy().tolist()\n",
    "    acc_rf = accuracy_score(trues_rf, preds_rf)\n",
    "    acc_cls = accuracy_score(trues_cls, preds_cls)\n",
    "    print(f\"Real/Fake Accuracy: {acc_rf:.4f}, Class Accuracy: {acc_cls:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "796b2bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 3750/3750 [13:44<00:00,  4.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real/Fake Accuracy: 0.9440, Class Accuracy: 0.9961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(model, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d91ff671",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_test(model, test_dir, output_csv=\"test.csv\"):\n",
    "    model.eval()\n",
    "    transform_test = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "    ])\n",
    "\n",
    "    test_images = [img for img in os.listdir(test_dir) if img.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    results = []\n",
    "\n",
    "    for img_name in tqdm(test_images, desc=\"Predicting Test Images\"):\n",
    "        img_path = os.path.join(test_dir, img_name)\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        image = transform_test(image).unsqueeze(0).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            out_real_fake, out_class = model(image)\n",
    "            label = 1 if out_real_fake.item() > 0.5 else 0\n",
    "            cls_idx = torch.argmax(out_class, dim=1).item()\n",
    "            cls_name = ['human_faces', 'animals', 'vehicles'][cls_idx]\n",
    "            results.append([img_name, label, cls_name])\n",
    "\n",
    "    df = pd.DataFrame(results, columns=['image', 'label', 'class'])\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"Saved predictions to {output_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b904aa83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting Test Images: 100%|██████████| 12002/12002 [9:27<00:00,  14.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved predictions to test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "predict_test(model, \"ArtiFact_240K/test\", output_csv=\"test.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
